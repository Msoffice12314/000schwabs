version: '3.8'

services:
  # Main Application
  app:
    build: 
      context: .
      dockerfile: Dockerfile
      args:
        - BUILDKIT_INLINE_CACHE=1
    image: schwab-ai-trading:latest
    container_name: schwab-trading-app
    restart: unless-stopped
    ports:
      - "${PORT:-5000}:5000"
    environment:
      - FLASK_ENV=${ENVIRONMENT:-development}
      - DATABASE_URL=postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DB:-schwab_trading}
      - REDIS_URL=redis://redis:6379/0
    env_file:
      - .env
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./models:/app/models
      - ./backups:/app/backups
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - schwab-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          memory: ${MAX_MEMORY:-2g}
          cpus: '${MAX_CPU:-2.0}'
        reservations:
          memory: 512m
          cpus: '0.5'

  # Data Collector Service
  data-collector:
    build: 
      context: .
      dockerfile: Dockerfile
    image: schwab-ai-trading:latest
    container_name: schwab-data-collector
    restart: unless-stopped
    command: python data_collector_daemon.py
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DB:-schwab_trading}
      - REDIS_URL=redis://redis:6379/0
    env_file:
      - .env
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - schwab-network
    deploy:
      resources:
        limits:
          memory: 1g
          cpus: '1.0'
        reservations:
          memory: 256m
          cpus: '0.25'

  # AI Model Trainer Service
  trainer:
    build: 
      context: .
      dockerfile: Dockerfile
    image: schwab-ai-trading:latest
    container_name: schwab-trainer
    restart: "no"  # Only run when explicitly started
    command: python trainer.py
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DB:-schwab_trading}
      - REDIS_URL=redis://redis:6379/0
    env_file:
      - .env
    volumes:
      - ./data:/app/data
      - ./models:/app/models
      - ./logs:/app/logs
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - schwab-network
    deploy:
      resources:
        limits:
          memory: 4g
          cpus: '4.0'
        reservations:
          memory: 1g
          cpus: '1.0'

  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: schwab-postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-schwab_trading}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_INITDB_ARGS: "--auth-host=scram-sha-256"
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/init:/docker-entrypoint-initdb.d
      - ./database/backups:/backups
    networks:
      - schwab-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres} -d ${POSTGRES_DB:-schwab_trading}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 1g
          cpus: '1.0'
        reservations:
          memory: 256m
          cpus: '0.25'

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: schwab-redis
    restart: unless-stopped
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD:-}
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis_data:/data
      - ./redis/redis.conf:/etc/redis/redis.conf:ro
    networks:
      - schwab-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          memory: 512m
          cpus: '0.5'
        reservations:
          memory: 128m
          cpus: '0.1'

  # Nginx Reverse Proxy
  nginx:
    image: nginx:alpine
    container_name: schwab-nginx
    restart: unless-stopped
    ports:
      - "${NGINX_HTTP_PORT:-80}:80"
      - "${NGINX_HTTPS_PORT:-443}:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ./static:/var/www/static:ro
    depends_on:
      - app
    networks:
      - schwab-network
    deploy:
      resources:
        limits:
          memory: 256m
          cpus: '0.5'
        reservations:
          memory: 64m
          cpus: '0.1'

  # Monitoring with Prometheus
  prometheus:
    image: prom/prometheus:latest
    container_name: schwab-prometheus
    restart: unless-stopped
    ports:
      - "${PROMETHEUS_PORT:-9090}:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    networks:
      - schwab-network
    profiles:
      - monitoring
    deploy:
      resources:
        limits:
          memory: 512m
          cpus: '0.5'
        reservations:
          memory: 128m
          cpus: '0.1'

  # Grafana Dashboard
  grafana:
    image: grafana/grafana:latest
    container_name: schwab-grafana
    restart: unless-stopped
    ports:
      - "${GRAFANA_PORT:-3000}:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
    depends_on:
      - prometheus
    networks:
      - schwab-network
    profiles:
      - monitoring
    deploy:
      resources:
        limits:
          memory: 256m
          cpus: '0.5'
        reservations:
          memory: 64m
          cpus: '0.1'

  # Jupyter Notebook for Analysis
  jupyter:
    build: 
      context: .
      dockerfile: Dockerfile.jupyter
    image: schwab-ai-trading-jupyter:latest
    container_name: schwab-jupyter
    restart: unless-stopped
    ports:
      - "${JUPYTER_PORT:-8888}:8888"
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - JUPYTER_TOKEN=${JUPYTER_TOKEN:-schwab-trading}
      - DATABASE_URL=postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DB:-schwab_trading}
    env_file:
      - .env
    volumes:
      - ./notebooks:/home/jovyan/work
      - ./data:/home/jovyan/data
      - ./models:/home/jovyan/models
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - schwab-network
    profiles:
      - development
    deploy:
      resources:
        limits:
          memory: 2g
          cpus: '2.0'
        reservations:
          memory: 512m
          cpus: '0.5'

  # Celery Worker for Background Tasks
  celery-worker:
    build: 
      context: .
      dockerfile: Dockerfile
    image: schwab-ai-trading:latest
    container_name: schwab-celery-worker
    restart: unless-stopped
    command: celery -A app.celery worker --loglevel=info --concurrency=4
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DB:-schwab_trading}
      - REDIS_URL=redis://redis:6379/0
    env_file:
      - .env
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./models:/app/models
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - schwab-network
    deploy:
      resources:
        limits:
          memory: 1g
          cpus: '1.0'
        reservations:
          memory: 256m
          cpus: '0.25'

  # Celery Beat Scheduler
  celery-beat:
    build: 
      context: .
      dockerfile: Dockerfile
    image: schwab-ai-trading:latest
    container_name: schwab-celery-beat
    restart: unless-stopped
    command: celery -A app.celery beat --loglevel=info
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DB:-schwab_trading}
      - REDIS_URL=redis://redis:6379/0
    env_file:
      - .env
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - schwab-network
    deploy:
      resources:
        limits:
          memory: 256m
          cpus: '0.5'
        reservations:
          memory: 64m
          cpus: '0.1'

  # Flower for Celery Monitoring
  flower:
    build: 
      context: .
      dockerfile: Dockerfile
    image: schwab-ai-trading:latest
    container_name: schwab-flower
    restart: unless-stopped
    command: celery -A app.celery flower --port=5555
    ports:
      - "${FLOWER_PORT:-5555}:5555"
    environment:
      - REDIS_URL=redis://redis:6379/0
    env_file:
      - .env
    depends_on:
      - redis
    networks:
      - schwab-network
    profiles:
      - monitoring
    deploy:
      resources:
        limits:
          memory: 256m
          cpus: '0.5'
        reservations:
          memory: 64m
          cpus: '0.1'

  # ElasticSearch for Logging
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.9.0
    container_name: schwab-elasticsearch
    restart: unless-stopped
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
      - xpack.security.enabled=false
    ports:
      - "${ELASTICSEARCH_PORT:-9200}:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    networks:
      - schwab-network
    profiles:
      - logging
    deploy:
      resources:
        limits:
          memory: 1g
          cpus: '1.0'
        reservations:
          memory: 512m
          cpus: '0.5'

  # Kibana for Log Visualization
  kibana:
    image: docker.elastic.co/kibana/kibana:8.9.0
    container_name: schwab-kibana
    restart: unless-stopped
    ports:
      - "${KIBANA_PORT:-5601}:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      - elasticsearch
    networks:
      - schwab-network
    profiles:
      - logging
    deploy:
      resources:
        limits:
          memory: 512m
          cpus: '0.5'
        reservations:
          memory: 256m
          cpus: '0.25'

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  elasticsearch_data:
    driver: local

networks:
  schwab-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

# Docker Compose Profiles:
# - default: app, postgres, redis, data-collector
# - monitoring: + prometheus, grafana, flower
# - development: + jupyter
# - logging: + elasticsearch, kibana
# - full: all services

# Usage Examples:
# docker-compose up -d                                    # Start core services
# docker-compose --profile monitoring up -d               # Start with monitoring
# docker-compose --profile development up -d              # Start with development tools
# docker-compose --profile logging up -d                  # Start with logging stack
# docker-compose --profile monitoring --profile logging up -d  # Multiple profiles

# Management Commands:
# docker-compose exec app python manage.py db upgrade     # Run database migrations
# docker-compose exec app python trainer.py              # Run model training
# docker-compose exec postgres pg_dump schwab_trading > backup.sql  # Database backup
# docker-compose logs -f app                             # View application logs
# docker-compose restart app                             # Restart application
# docker-compose down && docker-compose up -d            # Full restart

# Scaling Services:
# docker-compose up -d --scale celery-worker=3           # Scale workers
# docker-compose up -d --scale data-collector=2          # Scale data collectors

# Development Workflow:
# 1. docker-compose --profile development up -d          # Start dev environment
# 2. docker-compose exec app python manage.py db upgrade # Setup database
# 3. docker-compose exec app python trainer.py          # Train initial models
# 4. Visit http://localhost:5000 for the web interface
# 5. Visit http://localhost:8888 for Jupyter notebooks
# 6. Visit http://localhost:3000 for Grafana dashboards

# Production Deployment Notes:
# - Use external databases in production
# - Enable SSL/TLS with proper certificates
# - Set up proper backup strategies
# - Monitor resource usage and scale accordingly
# - Use secrets management for sensitive data
# - Enable log rotation and monitoring
# - Set up health checks and alerting